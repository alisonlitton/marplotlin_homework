{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations and Insights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 When reviewing the information you can see that the most successful drug regimens are\n",
    "#..Capomulin and Ramicane. This is observed by looking at the box and wnisker plot and seeing \n",
    "#..that the tumor volume at the end of the treatment was much smaller than the other drugs it \n",
    "#..was compared to. \n",
    "#2  The line plot used for the Capomulin drug treatment showed a significant decrese in tumor \n",
    "#..volume over time. \n",
    "#3 After completing the linear regression, we can see that the heavier the mouse,\n",
    "#..the higher the tumor volume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/Mouse_metadata.csv does not exist: 'data/Mouse_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a20c3979732b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Read the mouse data and the study results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmouse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmouse_metadata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mstudy_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_results_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data/Mouse_metadata.csv does not exist: 'data/Mouse_metadata.csv'"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import scipy.stats as linregress\n",
    "\n",
    "# Study data files\n",
    "mouse_metadata_path = \"data/Mouse_metadata.csv\"\n",
    "study_results_path = \"data/Study_results.csv\"\n",
    "\n",
    "# Read the mouse data and the study results\n",
    "mouse_metadata = pd.read_csv(mouse_metadata_path)\n",
    "study_results = pd.read_csv(study_results_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data into a single dataset\n",
    "mouse_data = \"Data/Mouse_metadata.csv\"\n",
    "study_data = \"Data/Study_results.csv\"\n",
    "mouse_data_df = pd.read_csv(mouse_data)\n",
    "study_data_df = pd.read_csv(study_data)\n",
    "#mouse_data_df\n",
    "#study_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the duplicate mice by ID number that shows up for Mouse ID and Timepoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.merge(mouse_data_df,study_data_df, how=\"left\", on=\"Mouse ID\")\n",
    "# Display the data table for preview\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of mice.\n",
    "combined_data[\"Mouse ID\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the duplicate mice by ID number that shows up for Mouse ID and Timepoint. \n",
    "total_unique_mice = combined_data[\"Mouse ID\"].unique()\n",
    "count_unique_mice = pd.DataFrame(total_unique_mice).count()\n",
    "count_unique_mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean DataFrame by dropping the duplicate mouse by its ID.\n",
    "dup_mice = combined_data.loc[combined_data.duplicated(subset = [\"Mouse ID\",\"Timepoint\"]),\"Mouse ID\"].unique()\n",
    "#dup_mice\n",
    "# Checking the number of mice in the clean DataFrame.\n",
    "clean_df = combined_data[combined_data[\"Mouse ID\"].isin(dup_mice)==False]\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Get all the data for the duplicate mouse ID. \n",
    "dup_mice_df = combined_data[combined_data[\"Mouse ID\"].isin(dup_mice)==True]\n",
    "dup_mice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen\n",
    "mean = combined_data.groupby(\"Drug Regimen\")[\"Tumor Volume (mm3)\"].mean()\n",
    "median = combined_data.groupby(\"Drug Regimen\")[\"Tumor Volume (mm3)\"].median()\n",
    "variance = combined_data.groupby(\"Drug Regimen\")[\"Tumor Volume (mm3)\"].var()\n",
    "stdv = combined_data.groupby(\"Drug Regimen\")[\"Tumor Volume (mm3)\"].std()\n",
    "sem = combined_data.groupby(\"Drug Regimen\")[\"Tumor Volume (mm3)\"].sem()\n",
    "\n",
    "# This method is the most straighforward, creating multiple series and putting them all together at the end.\n",
    "summary_df = pd.DataFrame({\"Mean\": mean, \"Median\": median, \"Variance\": variance, \"Standard Deviation\": stdv, \n",
    "                          \"SEM\": sem})\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen\n",
    "summary_stats = combined_data.groupby(\"Drug Regimen\")[\"Tumor Volume (mm3)\"].describe()\n",
    "summary_stats\n",
    "# This method produces everything in a single groupby function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar and Pie Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar plot showing the total number of mice for each treatment throughout the course of the study using pandas. \n",
    "grouped_df = pd.DataFrame(clean_df.groupby([\"Drug Regimen\"]).count()).reset_index()\n",
    "regimen = grouped_df[[\"Mouse ID\",\"Drug Regimen\"]]\n",
    "regimen = regimen.set_index(\"Drug Regimen\")\n",
    "regimen.plot(kind=\"bar\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar plot showing the total number of mice for each treatment throughout the course of the study using pyplot.\n",
    "drugs = summary_stats.index.tolist()\n",
    "#drugs\n",
    "regimen_count = (clean_df.groupby([\"Drug Regimen\"])[\"Age_months\"].count())\n",
    "regimen_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(len(regimen_count))\n",
    "x_axis = drugs\n",
    "plt.bar(x_axis, regimen_count, alpha=1,align=\"center\")\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.xlabel(\"Drug Regimen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pie plot showing the distribution of female versus male mice using pandas\n",
    "gender_pie_pd =pd.DataFrame(clean_df.groupby([\"Sex\"]).count()).reset_index()\n",
    "gender_pie_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_pie_pd = gender_pie_pd[[\"Sex\",\"Mouse ID\"]]\n",
    "#gender_pie_pd\n",
    "gender_pie_pd.plot(kind=\"pie\",y=\"Mouse ID\", autopct=\"%1.1f%%\", labels=gender_pie_pd[\"Sex\"], title=\"Sex\", legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pie plot showing the distribution of female versus male mice using pyplot\n",
    "gender_pie_py = (clean_df.groupby([\"Sex\"])[\"Age_months\"].count()).tolist()\n",
    "#gender_pie_py\n",
    "labels = [\"Females\",\"Males\"]\n",
    "colors = [\"orange\",\"blue\"]\n",
    "plt.pie(gender_pie_py, labels=labels,colors=colors,autopct=\"%1.1f%%\",startangle=140)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quartiles, Outliers and Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the final tumor volume of each mouse across four of the treatment regimens:  \n",
    "# Capomulin, Ramicane, Infubinol, and Ceftamin\n",
    "# Start by getting the last (greatest) timepoint for each mouse\n",
    "# Merge this group df with the original dataframe to get the tumor volume at the last timepoint\n",
    "cap_df = clean_df.loc[clean_df[\"Drug Regimen\"] == \"Capomulin\",:]\n",
    "ram_df = clean_df.loc[clean_df[\"Drug Regimen\"] == \"Ramicane\", :]\n",
    "inf_df = clean_df.loc[clean_df[\"Drug Regimen\"] == \"Infubinol\", :]\n",
    "cef_df = clean_df.loc[clean_df[\"Drug Regimen\"] == \"Ceftamin\", :]\n",
    "#cap_df\n",
    "#ram_df\n",
    "#inf_df\n",
    "#cef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capomulin greatest timepoint \n",
    "cap_last = cap_df.groupby(\"Mouse ID\").max()[\"Timepoint\"]\n",
    "#cap_last\n",
    "cap_vol = pd.DataFrame(cap_last)\n",
    "cap_merge = pd.merge(cap_vol, clean_df, on=(\"Mouse ID\",\"Timepoint\"),how=\"left\")\n",
    "cap_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ramicane greatest timepoint\n",
    "ram_last = ram_df.groupby(\"Mouse ID\").max()[\"Timepoint\"]\n",
    "#ram_last\n",
    "ram_vol = pd.DataFrame(ram_last)\n",
    "ram_merge = pd.merge(ram_vol, clean_df, on=(\"Mouse ID\",\"Timepoint\"),how=\"left\")\n",
    "ram_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infubinol greatest timepoint \n",
    "inf_last = inf_df.groupby(\"Mouse ID\").max()[\"Timepoint\"]\n",
    "inf_last\n",
    "inf_vol = pd.DataFrame(inf_last)\n",
    "inf_merge = pd.merge(inf_vol, clean_df, on=(\"Mouse ID\",\"Timepoint\"),how=\"left\")\n",
    "inf_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ceftamin greatest timepoint \n",
    "cef_last = cef_df.groupby(\"Mouse ID\").max()[\"Timepoint\"]\n",
    "#cap_last\n",
    "cef_vol = pd.DataFrame(cef_last)\n",
    "cef_merge = pd.merge(cef_vol, clean_df, on=(\"Mouse ID\",\"Timepoint\"),how=\"left\")\n",
    "cef_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR and quantitatively determine if there are any potential outliers. \n",
    "# Determine if there are any potential outliers \n",
    "# Determine outliers using upper and lower bounds\n",
    "#Capomulin\n",
    "cap_tumors = cap_merge[\"Tumor Volume (mm3)\"]\n",
    "cap_tumors\n",
    "quartiles = cap_tumors.quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of Capomulin tumor treatment is: {lowerq}\")\n",
    "print(f\"The upper quartile of Capomulin tumor treatment is: {upperq}\")\n",
    "print(f\"The interquartile range of Capomulin tumor treatment is: {iqr}\")\n",
    "print(f\"The the median of Capomulin tumor treatment is: {quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR and quantitatively determine if there are any potential outliers. \n",
    "# Determine if there are any potential outliers \n",
    "# Determine outliers using upper and lower bounds\n",
    "#Ramicane\n",
    "ram_tumors = ram_merge[\"Tumor Volume (mm3)\"]\n",
    "ram_tumors\n",
    "quartiles = ram_tumors.quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of Ramicane tumor treatment is: {lowerq}\")\n",
    "print(f\"The upper quartile of Ramicane tumor treatment is: {upperq}\")\n",
    "print(f\"The interquartile range of Ramicane tumor treatment is: {iqr}\")\n",
    "print(f\"The the median of Ramicane tumor treatment is: {quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR and quantitatively determine if there are any potential outliers. \n",
    "# Determine if there are any potential outliers \n",
    "# Determine outliers using upper and lower bounds\n",
    "#Infubinol\n",
    "inf_tumors = inf_merge[\"Tumor Volume (mm3)\"]\n",
    "inf_tumors\n",
    "quartiles = inf_tumors.quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of Infubinol tumor treatment is: {lowerq}\")\n",
    "print(f\"The upper quartile of Infubinol tumor treatment is: {upperq}\")\n",
    "print(f\"The interquartile range of Infubinol tumor treatment is: {iqr}\")\n",
    "print(f\"The the median of Infubinol tumor treatment is: {quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR and quantitatively determine if there are any potential outliers. \n",
    "# Determine if there are any potential outliers \n",
    "# Determine outliers using upper and lower bounds\n",
    "#Ceftamin\n",
    "cef_tumors = cef_merge[\"Tumor Volume (mm3)\"]\n",
    "cef_tumors\n",
    "quartiles = cef_tumors.quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of Ceftamin tumor treatment is: {lowerq}\")\n",
    "print(f\"The upper quartile of Ceftamin tumor treatment is: {upperq}\")\n",
    "print(f\"The interquartile range of Ceftamin tumor treatment is: {iqr}\")\n",
    "print(f\"The the median of Ceftamin tumor treatment is: {quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put treatments into a list for for loop (and later for plot labels)\n",
    "# Create empty list to fill with tumor vol data (for plotting)\n",
    "# Calculate the IQR and quantitatively determine if there are any potential outliers. \n",
    "    # Locate the rows which contain mice on each drug and get the tumor volumes\n",
    "    # add subset     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a box plot of the final tumor volume of each mouse across four regimens of interest\n",
    "\n",
    "tumor_data = [cap_tumors, ram_tumors, inf_tumors, cef_tumors]\n",
    "Regimen= ['Capomulin', 'Ramicane', 'Infubinol','Ceftamin']\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_ylabel('Final Tumor Volume (mm3)')\n",
    "ax1.set_xlabel('Drug')\n",
    "ax1.boxplot(tumor_data, labels=Regimen)\n",
    "\n",
    "plt.ylim(15, 75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line and Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a line plot of time point versus tumor volume for a mouse treated with Capomulin\n",
    "cap_line = cap_df.loc[cap_df[\"Mouse ID\"]==\"l509\",:]\n",
    "cap_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = cap_line[\"Timepoint\"]\n",
    "y_axis = cap_line[\"Tumor Volume (mm3)\"]\n",
    "plt.title(\"Capomulin treatment of mouse l509\")\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.xlabel(\"Timepoint (days)\")\n",
    "plt.ylabel(\"Tumor Volume (mm3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a scatter plot of mouse weight versus average tumor volume for the Capomulin regimen\n",
    "avg_cap = pd.DataFrame(cap_df.groupby([\"Mouse ID\", \"Weight (g)\"])[\"Tumor Volume (mm3)\"].mean()).reset_index()\n",
    "avg_cap = avg_cap.rename(columns={\"Tumor Volume (mm3)\":\"Average Tumor Volume (mm3)\"})\n",
    "avg_cap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(avg_cap[\"Weight (g)\"],avg_cap[\"Average Tumor Volume (mm3)\"])\n",
    "plt.xlabel(\"Weight (g)\")\n",
    "plt.ylabel(\"Average Tumor Volume (mm3)\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficient and linear regression model \n",
    "# for mouse weight and average tumor volume for the Capomulin regimen\n",
    "cap_weight = cap_df.groupby([\"Mouse ID\"])[\"Weight (g)\"].mean()\n",
    "#cap_weight\n",
    "cap_tumor = cap_df.groupby([\"Mouse ID\"])[\"Tumor Volume (mm3)\"].mean()\n",
    "#cap_tumor\n",
    "print(f\"The correlation coefficient between mouse weight and average tumor volume is {round(st.pearsonr(cap_weight,cap_tumor)[0],2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "x_values = avg_cap[\"Weight (g)\"]\n",
    "y_values = avg_cap[\"Average Tumor Volume (mm3)\"]\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x_values,y_values)\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(6,10),fontsize=15,color=\"red\")\n",
    "plt.xlabel(\"Weight (g)\")\n",
    "plt.ylabel(\"Average Tumor Volume (mm3)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
